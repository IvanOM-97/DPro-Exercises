{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP55Q4yW8Caz6HKM9sjRZ9w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanOM-97/DPro-Exercises/blob/master/U43T2C92CNN2SeriesAssignments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynIwLtMgmMqu"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "SIMPLE CONV 2D\n",
        "  Build a 2d CNN using only minimal libraries like numpy\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROBLEMA 1 - CREANDO UNA CAPA CONVOLUCIONAL 2D\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Conv2D:\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, learning_rate=0.01):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kh, self.kw = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.lr = learning_rate\n",
        "\n",
        "        # Xavier initialization\n",
        "        scale = np.sqrt(1. / (in_channels * self.kh * self.kw))\n",
        "        self.W = np.random.randn(out_channels, in_channels, self.kh, self.kw) * scale\n",
        "        self.b = np.zeros(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = (H + 2 * self.padding - self.kh) // self.stride + 1\n",
        "        out_w = (W + 2 * self.padding - self.kw) // self.stride + 1\n",
        "        self.out_shape = (N, self.out_channels, out_h, out_w)\n",
        "        if self.padding > 0:\n",
        "            x = np.pad(x, ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)), mode='constant')\n",
        "\n",
        "        self.x_padded = x\n",
        "        out = np.zeros((N, self.out_channels, out_h, out_w))\n",
        "        for n in range(N):\n",
        "            for oc in range(self.out_channels):\n",
        "                for i in range(out_h):\n",
        "                    for j in range(out_w):\n",
        "                        h_start = i * self.stride\n",
        "                        h_end = h_start + self.kh\n",
        "                        w_start = j * self.stride\n",
        "                        w_end = w_start + self.kw\n",
        "                        region = x[n, :, h_start:h_end, w_start:w_end]\n",
        "                        out[n, oc, i, j] = np.sum(region * self.W[oc]) + self.b[oc]\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        N, C, H, W = self.x.shape\n",
        "        dx = np.zeros_like(self.x_padded, dtype=np.float32)\n",
        "        dW = np.zeros_like(self.W, dtype=np.float32)\n",
        "        db = np.zeros_like(self.b, dtype=np.float32)\n",
        "\n",
        "        _, _, out_h, out_w = dout.shape\n",
        "        for n in range(N):\n",
        "            for oc in range(self.out_channels):\n",
        "                for i in range(out_h):\n",
        "                    for j in range(out_w):\n",
        "                        h_start = i * self.stride\n",
        "                        h_end = h_start + self.kh\n",
        "                        w_start = j * self.stride\n",
        "                        w_end = w_start + self.kw\n",
        "                        region = self.x_padded[n, :, h_start:h_end, w_start:w_end]\n",
        "\n",
        "                        dW[oc] += region * dout[n, oc, i, j]\n",
        "                        db[oc] += dout[n, oc, i, j]\n",
        "                        dx[n, :, h_start:h_end, w_start:w_end] += self.W[oc] * dout[n, oc, i, j]\n",
        "\n",
        "        # Removing padding if added\n",
        "        if self.padding > 0:\n",
        "            dx = dx[:, :, self.padding:-self.padding, self.padding:-self.padding]\n",
        "\n",
        "        # Updating weigts\n",
        "        self.W -= self.lr * dW\n",
        "        self.b -= self.lr * db\n",
        "\n",
        "        return dx\n",
        "\n",
        "# PROBLEMA 2 - EXPERIMENTA CON CAPAS CONVOLUCIONALES 2D EN PEQUEÑOS ARRAYS\n",
        "# Input the data when flowing CNN2 forwards (1,1,4,4)\n",
        "x = np.array([[[[ 1,  2,  3,  4],\n",
        "                [ 5,  6,  7,  8],\n",
        "                [ 9, 10, 11, 12],\n",
        "                [13, 14, 15, 16]]]])\n",
        "\n",
        "# Manually setting filters\n",
        "w = np.array([[[[ 0,  0,  0], [ 0,  1,  0], [ 0, -1,  0]]],\n",
        "              [[[ 0,  0,  0], [ 0, -1,  1], [ 0,  0,  0]]]]).astype(np.float32)\n",
        "\n",
        "b = np.array([0, 0], dtype=np.float32)\n",
        "\n",
        "# Conv2d with 1 input channel, 2 outputs channels, kernel 3x3\n",
        "conv = Conv2D(in_channels=1, out_channels=2, kernel_size=(3,3), stride=1, padding=0)\n",
        "conv.W = w.copy()\n",
        "conv.b = b.copy()\n",
        "\n",
        "# Forward pass\n",
        "out = conv.forward(x)\n",
        "print(\"forward output: \\n\", out)\n",
        "\n",
        "# Backward test\n",
        "dout = np.array([[[[ -4,  -4], [ -4,  -4]],\n",
        "                  [[  1,  -7], [  1, -11]]]], dtype = np.float32)\n",
        "dx = conv.backward(dout)\n",
        "print(\"backward output: \\n\", dx)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFgcm5gKorFM",
        "outputId": "f5977609-eb1e-49cf-f2f2-e1e0ed86a3f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward output: \n",
            " [[[[-4. -4.]\n",
            "   [-4. -4.]]\n",
            "\n",
            "  [[ 1.  1.]\n",
            "   [ 1.  1.]]]]\n",
            "backward output: \n",
            " [[[[  0.   0.   0.   0.]\n",
            "   [  0.  -5.   4.  -7.]\n",
            "   [  0.  -1.  12. -11.]\n",
            "   [  0.   4.   4.   0.]]]]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROBLEMA 3 - TAMAÑO DE SALIDA DEPUES DE LA CONVOLUCION 2D\n",
        "def conv2d_output_size(H_in, W_in, kernel_size, stride=1, padding=0):\n",
        "    kh, kw = kernel_size\n",
        "    H_out = (H_in + 2 * padding - kh) // stride + 1\n",
        "    W_out = (W_in + 2 * padding - kw) // stride + 1\n",
        "    return H_out, W_out\n",
        "\n",
        "# PROBLEMA 4 - CREANDO UNA CAPA MAX POOLING\n",
        "class MaxPool2D:\n",
        "    def __init__(self, pool_size=(2,2), stride=2):\n",
        "        self.ph, self.pw = pool_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = (H - self.ph) // self.stride + 1\n",
        "        out_w = (W - self.pw) // self.stride + 1\n",
        "        self.arg_max = np.zeros((N, C, out_h, out_w), dtype=np.int32)\n",
        "\n",
        "        out = np.zeros((N, C, out_h, out_w))\n",
        "\n",
        "        for n in range(N):\n",
        "            for c in range(C):\n",
        "                for i in range(out_h):\n",
        "                    for j in range(out_w):\n",
        "                        h_start = i * self.stride\n",
        "                        w_start = j * self.stride\n",
        "                        window = x[n, c, h_start:h_start+self.ph, w_start:w_start+self.pw]\n",
        "                        out[n, c, i, j] = np.max(window)\n",
        "                        self.arg_max[n, c, i, j] = np.argmax(window)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        N, C, H, W = self.x.shape\n",
        "        out_h, out_w = dout.shape[2:]\n",
        "        dx = np.zeros_like(self.x)\n",
        "\n",
        "        for n in range(N):\n",
        "            for c in range(C):\n",
        "                for i in range(out_h):\n",
        "                    for j in range(out_w):\n",
        "                        h_start = i * self.stride\n",
        "                        w_start = j * self.stride\n",
        "                        index = self.arg_max[n, c, i, j]\n",
        "                        h_index = h_start + index // self.pw\n",
        "                        w_index = w_start + index % self.pw\n",
        "                        dx[n, c, h_index, w_index] += dout[n, c, i, j]\n",
        "\n",
        "        return dx\n",
        "\n",
        "# PROBLEMA 5 - CREANDO UN AVERAGE POOLING\n",
        "class AveragePool2D:\n",
        "    def __init__(self, pool_size=(2,2), stride=2):\n",
        "        self.ph, self.pw = pool_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = (H - self.ph) // self.stride + 1\n",
        "        out_w = (W - self.pw) // self.stride + 1\n",
        "\n",
        "        out = np.zeros((N, C, out_h, out_w))\n",
        "\n",
        "        for n in range(N):\n",
        "            for c in range(C):\n",
        "                for i in range(out_h):\n",
        "                    for j in range(out_w):\n",
        "                        h_start = i * self.stride\n",
        "                        w_start = j * self.stride\n",
        "                        window = x[n, c, h_start:h_start+self.ph, w_start:w_start+self.pw]\n",
        "                        out[n, c, i, j] = np.mean(window)\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        N, C, H, W = self.x.shape\n",
        "        out_h, out_w = dout.shape[2:]\n",
        "        dx = np.zeros_like(self.x)\n",
        "\n",
        "        for n in range(N):\n",
        "            for c in range(C):\n",
        "                for i in range(out_h):\n",
        "                    for j in range(out_w):\n",
        "                        h_start = i * self.stride\n",
        "                        w_start = j * self.stride\n",
        "                        dx[n, c, h_start:h_start+self.ph, w_start:w_start+self.pw] += dout[n, c, i, j] / (self.ph * self.pw)\n",
        "        return dx\n",
        "\n",
        "# PROBLEMA 6 - SMOOTHIN O FLATTENING\n",
        "class Flatten:\n",
        "    def forward(self, x):\n",
        "        self.orig_shape = x.shape\n",
        "        return x.reshape(x.shape[0], -1)\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return dout.reshape(self.orig_shape)\n",
        "\n",
        "# PROBLEMA 7 - APRENDIZAJE Y ESTIMACION\n",
        "class ReLU:\n",
        "    def forward(self, x):\n",
        "        self.mask = (x > 0)\n",
        "        return x * self.mask\n",
        "\n",
        "    def backward(self, dout):\n",
        "        return dout * self.mask\n",
        "\n",
        "class Dense:\n",
        "    def __init__(self, in_features, out_features, lr=0.01):\n",
        "        scale = np.sqrt(1. / in_features)\n",
        "        self.W = np.random.randn(in_features, out_features) * scale\n",
        "        self.b = np.zeros(out_features)\n",
        "        self.lr = lr\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        return np.dot(x, self.W) + self.b\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dW = np.dot(self.x.T, dout)\n",
        "        db = np.sum(dout, axis=0)\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.W -= self.lr * dW\n",
        "        self.b -= self.lr * db\n",
        "        return dx\n",
        "\n",
        "class SoftmaxCrossEntropy:\n",
        "    def forward(self, x, y):\n",
        "        self.y = y\n",
        "        self.y_pred = self._softmax(x)\n",
        "        return self._cross_entropy(self.y_pred, y)\n",
        "\n",
        "    def backward(self):\n",
        "        return (self.y_pred - self.y) / self.y.shape[0]\n",
        "\n",
        "    def _softmax(self, x):\n",
        "        x = x - np.max(x, axis=1, keepdims=True)\n",
        "        return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
        "\n",
        "    def _cross_entropy(self, y_pred, y_true):\n",
        "        return -np.sum(y_true * np.log(y_pred + 1e-7)) / y_true.shape[0]\n",
        "\n",
        "# Preprocess MNIST\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train[:1000].astype(np.float32) / 255.0\n",
        "x_test = x_test[:200].astype(np.float32) / 255.0\n",
        "y_train = to_categorical(y_train[:1000], 10)\n",
        "y_test = to_categorical(y_test[:200], 10)\n",
        "\n",
        "x_train = x_train.reshape(-1, 1, 28, 28)\n",
        "x_test = x_test.reshape(-1, 1, 28, 28)\n",
        "\n",
        "# Define simple CNN\n",
        "class Scratch2dCNNClassifier:\n",
        "    def __init__(self):\n",
        "        self.conv = Conv2D(in_channels=1, out_channels=8, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.relu1 = ReLU()\n",
        "        self.pool = MaxPool2D(pool_size=(2,2), stride=2)\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = Dense(in_features=8*14*14, out_features=64)\n",
        "        self.relu2 = ReLU()\n",
        "        self.fc2 = Dense(in_features=64, out_features=10)\n",
        "        self.loss_fn = SoftmaxCrossEntropy()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv.forward(x)\n",
        "        x = self.relu1.forward(x)\n",
        "        x = self.pool.forward(x)\n",
        "        x = self.flatten.forward(x)\n",
        "        x = self.fc1.forward(x)\n",
        "        x = self.relu2.forward(x)\n",
        "        x = self.fc2.forward(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout = self.fc2.backward(dout)\n",
        "        dout = self.relu2.backward(dout)\n",
        "        dout = self.fc1.backward(dout)\n",
        "        dout = self.flatten.backward(dout)\n",
        "        dout = self.pool.backward(dout)\n",
        "        dout = self.relu1.backward(dout)\n",
        "        dout = self.conv.backward(dout)\n",
        "\n",
        "    def train(self, x, y):\n",
        "        out = self.forward(x)\n",
        "        loss = self.loss_fn.forward(out, y)\n",
        "        dout = self.loss_fn.backward()\n",
        "        self.backward(dout)\n",
        "        return loss\n",
        "\n",
        "    def predict(self, x):\n",
        "        out = self.forward(x)\n",
        "        return np.argmax(out, axis=1)\n",
        "\n",
        "# Training\n",
        "model = Scratch2dCNNClassifier()\n",
        "epochs = 3\n",
        "batch_size = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loss_sum = 0\n",
        "    for i in range(0, len(x_train), batch_size):\n",
        "        x_batch = x_train[i:i+batch_size]\n",
        "        y_batch = y_train[i:i+batch_size]\n",
        "        loss = model.train(x_batch, y_batch)\n",
        "        loss_sum += loss\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss_sum}\")\n",
        "\n",
        "# Accuracy\n",
        "preds = model.predict(x_test)\n",
        "true = np.argmax(y_test, axis=1)\n",
        "accuracy = np.mean(preds == true)\n",
        "print(f\"test Accuracy: {accuracy}\")\n",
        "print (\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEeXa_g-nLBN",
        "outputId": "a2481484-f929-4c20-ac11-1efe7916e518"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 22.582135571710477\n",
            "Epoch 2, Loss: 21.700429009594878\n",
            "Epoch 3, Loss: 20.91476362596005\n",
            "test Accuracy: 0.36\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROBLEMA 8 - LeNet\n",
        "class LeNet:\n",
        "    def __init__(self):\n",
        "        self.conv1 = Conv2D(in_channels=1, out_channels=6, kernel_size=(5,5), stride=1, padding=0)\n",
        "        self.relu1 = ReLU()\n",
        "        self.pool1 = MaxPool2D(pool_size=(2,2), stride=2)\n",
        "        self.conv2 = Conv2D(in_channels=6, out_channels=16, kernel_size=(5,5), stride=1, padding=0)\n",
        "        self.relu2 = ReLU()\n",
        "        self.pool2 = MaxPool2D(pool_size=(2,2), stride=2)\n",
        "        self.flatten = Flatten()\n",
        "        self.fc1 = Dense(in_features=16*4*4, out_features=120)\n",
        "        self.relu3 = ReLU()\n",
        "        self.fc2 = Dense(in_features=120, out_features=84)\n",
        "        self.relu4 = ReLU()\n",
        "        self.fc3 = Dense(in_features=84, out_features=10)\n",
        "        self.loss_fn = SoftmaxCrossEntropy()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1.forward(x)\n",
        "        x = self.relu1.forward(x)\n",
        "        x = self.pool1.forward(x)\n",
        "        x = self.conv2.forward(x)\n",
        "        x = self.relu2.forward(x)\n",
        "        x = self.pool2.forward(x)\n",
        "        x = self.flatten.forward(x)\n",
        "        x = self.fc1.forward(x)\n",
        "        x = self.relu3.forward(x)\n",
        "        x = self.fc2.forward(x)\n",
        "        x = self.relu4.forward(x)\n",
        "        x = self.fc3.forward(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout = self.fc3.backward(dout)\n",
        "        dout = self.relu4.backward(dout)\n",
        "        dout = self.fc2.backward(dout)\n",
        "        dout = self.relu3.backward(dout)\n",
        "        dout = self.fc1.backward(dout)\n",
        "        dout = self.flatten.backward(dout)\n",
        "        dout = self.pool2.backward(dout)\n",
        "        dout = self.relu2.backward(dout)\n",
        "        dout = self.conv2.backward(dout)\n",
        "        dout = self.pool1.backward(dout)\n",
        "        dout = self.relu1.backward(dout)\n",
        "        dout = self.conv1.backward(dout)\n",
        "\n",
        "    def train(self, x, y):\n",
        "        out = self.forward(x)\n",
        "        loss = self.loss_fn.forward(out, y)\n",
        "        dout = self.loss_fn.backward()\n",
        "        self.backward(dout)\n",
        "        return loss\n",
        "\n",
        "    def predict(self, x):\n",
        "        out = self.forward(x)\n",
        "        return np.argmax(out, axis=1)\n",
        "\n",
        "# Training LeNet\n",
        "lenet = LeNet()\n",
        "for epoch in range(3):\n",
        "    loss_sum = 0\n",
        "    for i in range(0, len(x_train), batch_size):\n",
        "        x_batch = x_train[i:i+batch_size]\n",
        "        y_batch = y_train[i:i+batch_size]\n",
        "        loss = lenet.train(x_batch, y_batch)\n",
        "        loss_sum += loss\n",
        "    print(f\"LeNet Epoch {epoch+1}, Loss: {loss_sum}\")\n",
        "\n",
        "preds = lenet.predict(x_test)\n",
        "true = np.argmax(y_test, axis=1)\n",
        "acc = np.mean(preds == true)\n",
        "print(f\"LeNet test Accuracy: {acc}\")\n",
        "print (\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ka6dPauteNU",
        "outputId": "c77b0959-4b66-46f6-bc82-5668a2fc5ad9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet Epoch 1, Loss: 23.36567468496213\n",
            "LeNet Epoch 2, Loss: 23.080396621170543\n",
            "LeNet Epoch 3, Loss: 22.81952163167631\n",
            "LeNet test Accuracy: 0.145\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PROBLEMA 10 - CALCULO DEL TAMAÑO DE SALIDA Y EL NUMERO DE PARAMETROS\n",
        "def compute_conv_output_and_params(H_in, W_in, C_in, kernel_size, C_out, stride=1, padding=0):\n",
        "    kh, kw = kernel_size\n",
        "\n",
        "    # Ouput dimensions\n",
        "    H_out = (H_in + 2 * padding - kh) // stride + 1\n",
        "    W_out = (W_in + 2 * padding - kw) // stride + 1\n",
        "\n",
        "    # Parameters per filter: C_in * kh * kw, plus 1 bias per output channel\n",
        "    params_per_filter = C_in * kh * kw + 1\n",
        "    total_params = params_per_filter * C_out\n",
        "\n",
        "    return (H_out, W_out, C_out), total_params\n",
        "\n",
        "# 1. input: 144x144x3, filter: 3x3, 6 filters, stride=1, padding=0\n",
        "out1, params1 = compute_conv_output_and_params(144, 144, 3, (3,3), 6)\n",
        "print(\"1. Output dimensions:\", out1)\n",
        "print(\"1. Number of parameters:\", params1)\n",
        "\n",
        "# 2. input: 60x60x24, filter: 3x3, 48 filters, stride=1, padding=0\n",
        "out2, params2 = compute_conv_output_and_params(60, 60, 24, (3,3), 48)\n",
        "print(\"2. Output dimensions:\", out2)\n",
        "print(\"2. Number of parameters:\", params2)\n",
        "\n",
        "# 3. input: 20x20x10, filter: 3x3, 20 filters, stride=2, padding=0\n",
        "out3, params3 = compute_conv_output_and_params(20, 20, 10, (3,3), 20, stride=2)\n",
        "print(\"3. Output dimensions:\", out3)\n",
        "print(\"3. Number of parameters:\", params3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWMJMQE08Gza",
        "outputId": "dbce84cd-d2c3-4e03-b36d-6373977aaabc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Output dimensions: (142, 142, 6)\n",
            "1. Number of parameters: 168\n",
            "2. Output dimensions: (58, 58, 48)\n",
            "2. Number of parameters: 10416\n",
            "3. Output dimensions: (9, 9, 20)\n",
            "3. Number of parameters: 1820\n"
          ]
        }
      ]
    }
  ]
}